#!/usr/bin/env python3
"""
Docker Monitor - Caching & Performance Layer
Author: David Smidke - Accenture
Generated by GitHub Copilot

Intelligent caching for expensive Docker operations with TTL support.
Green Software: Reduces redundant API calls and disk I/O.
"""

import asyncio
import logging
import time
from typing import Any, Callable, Dict, Optional, Tuple
from functools import wraps


class Cache:
    """TTL-based cache for expensive operations - Generated by GitHub Copilot"""
    
    def __init__(self, ttl_seconds: int = 60):
        """
        Initialize cache
        
        Args:
            ttl_seconds: Time to live for cache entries (default 60s)
        """
        self._data: Dict[str, Tuple[Any, float]] = {}
        self._ttl = ttl_seconds
        self._lock = asyncio.Lock()
        self._log = logging.getLogger(__name__)
    
    async def get(self, key: str) -> Optional[Any]:
        """Get value from cache if not expired"""
        async with self._lock:
            if key not in self._data:
                return None
            
            value, timestamp = self._data[key]
            if time.time() - timestamp > self._ttl:
                del self._data[key]
                return None
            
            return value
    
    async def set(self, key: str, value: Any) -> None:
        """Store value in cache"""
        async with self._lock:
            self._data[key] = (value, time.time())
    
    async def delete(self, key: str) -> None:
        """Delete cache entry"""
        async with self._lock:
            self._data.pop(key, None)
    
    async def clear(self) -> None:
        """Clear entire cache"""
        async with self._lock:
            self._data.clear()
    
    def get_stats(self) -> Dict[str, int]:
        """Get cache statistics"""
        expired_count = 0
        for key, (_, timestamp) in self._data.items():
            if time.time() - timestamp > self._ttl:
                expired_count += 1
        
        return {
            'total': len(self._data),
            'expired': expired_count,
            'active': len(self._data) - expired_count
        }


class SmartCommandCache(Cache):
    """Cache with in-flight command deduplication - Generated by GitHub Copilot"""
    
    def __init__(self, ttl_seconds: int = 60):
        super().__init__(ttl_seconds)
        self._in_flight: Dict[str, asyncio.Task] = {}
    
    async def run_once(self, key: str, command_func: Callable) -> Any:
        """
        Run command only once, reuse result if already running.
        
        Args:
            key: Cache key
            command_func: Async callable to execute
        
        Returns:
            Command result
        """
        # Check cache first
        cached = await self.get(key)
        if cached is not None:
            return cached
        
        # If already running, wait for it
        if key in self._in_flight:
            return await self._in_flight[key]
        
        # Otherwise schedule new task
        async def _run_and_cache():
            try:
                result = await command_func()
                await self.set(key, result)
                return result
            finally:
                if key in self._in_flight:
                    del self._in_flight[key]
        
        task = asyncio.create_task(_run_and_cache())
        self._in_flight[key] = task
        
        try:
            return await task
        except Exception as e:
            self._log.error(f"Smart cache error: {e}")
            raise



class CachedFunction:
    """Decorator for caching async functions - Green Software optimized"""
    
    def __init__(self, ttl_seconds: int = 60, key_builder: Optional[Callable] = None):
        """
        Initialize cached function decorator
        
        Args:
            ttl_seconds: Cache TTL
            key_builder: Optional function to build cache key from args/kwargs
        """
        self.ttl = ttl_seconds
        self.key_builder = key_builder or self._default_key_builder
        self._cache = Cache(ttl_seconds)
        self._log = logging.getLogger(__name__)
    
    @staticmethod
    def _default_key_builder(*args, **kwargs) -> str:
        """Build cache key from function args"""
        args_str = '_'.join(str(arg) for arg in args)
        kwargs_str = '_'.join(f"{k}={v}" for k, v in sorted(kwargs.items()))
        return f"{args_str}:{kwargs_str}".replace(' ', '_')
    
    def __call__(self, func: Callable) -> Callable:
        """Decorate async function"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache_key = self.key_builder(*args, **kwargs)
            
            # Check cache
            cached = await self._cache.get(cache_key)
            if cached is not None:
                self._log.debug(f"Cache hit: {func.__name__}({cache_key})")
                return cached
            
            # Execute function
            result = await func(*args, **kwargs)
            
            # Store in cache
            if result is not None:
                await self._cache.set(cache_key, result)
            
            return result
        
        setattr(wrapper, 'cache', self._cache)
        return wrapper


class CommandCache:
    """Specialized cache for Docker command outputs - Generated by GitHub Copilot"""
    
    def __init__(self):
        """Initialize command cache with different TTLs for different command types"""
        self._caches: Dict[str, Cache] = {
            'stats': Cache(ttl_seconds=10),      # Stats change frequently
            'ps': Cache(ttl_seconds=15),         # Container list
            'images': Cache(ttl_seconds=60),     # Images rarely change
            'inspect': Cache(ttl_seconds=30),    # Container details
            'volume': Cache(ttl_seconds=60),     # Volumes stable
            'network': Cache(ttl_seconds=60),    # Networks stable
            'compose': Cache(ttl_seconds=120),   # Compose files very stable
        }
        self._log = logging.getLogger(__name__)
    
    def _get_cache_type(self, command: str) -> str:
        """Determine cache type from docker command"""
        if 'stats' in command:
            return 'stats'
        elif 'ps' in command:
            return 'ps'
        elif 'images' in command:
            return 'images'
        elif 'inspect' in command:
            return 'inspect'
        elif 'volume' in command:
            return 'volume'
        elif 'network' in command:
            return 'network'
        elif 'compose' in command:
            return 'compose'
        return 'default'
    
    async def get(self, command: str) -> Optional[str]:
        """Get cached command output"""
        cache_type = self._get_cache_type(command)
        cache = self._caches.get(cache_type, self._caches['stats'])
        result = await cache.get(command)
        
        if result is not None:
            self._log.debug(f"Command cache hit: {command[:50]}")
        
        return result
    
    async def set(self, command: str, output: str) -> None:
        """Cache command output"""
        cache_type = self._get_cache_type(command)
        cache = self._caches.get(cache_type, self._caches['stats'])
        await cache.set(command, output)
    
    async def invalidate(self, pattern: str = "") -> None:
        """Invalidate cache entries matching pattern"""
        for cache_type, cache in self._caches.items():
            if not pattern or pattern in cache_type:
                await cache.clear()
    
    def get_stats(self) -> Dict[str, Dict[str, int]]:
        """Get cache statistics by type"""
        stats = {}
        for cache_type, cache in self._caches.items():
            stats[cache_type] = cache.get_stats()
        return stats


class BatchExecutor:
    """Batch and deduplicate Docker commands - Green Software optimization"""
    
    def __init__(self, timeout: int = 5):
        """Initialize batch executor"""
        self._timeout = timeout
        self._pending: Dict[str, asyncio.Task] = {}
        self._results: Dict[str, str] = {}
        self._log = logging.getLogger(__name__)
    
    async def execute_batch(self, commands: list) -> Dict[str, str]:
        """
        Execute multiple commands efficiently, deduplicating identical commands
        
        Args:
            commands: List of command lists
        
        Returns:
            Dict mapping command string to output
        """
        # Deduplicate commands
        unique_commands = {}
        for cmd in commands:
            cmd_str = ' '.join(cmd)
            if cmd_str not in unique_commands:
                unique_commands[cmd_str] = cmd
        
        if not unique_commands:
            return {}
        
        # Execute all unique commands in parallel
        results = {}
        tasks = {}
        
        for cmd_str, cmd in unique_commands.items():
            task = asyncio.create_task(self._run_command(cmd))
            tasks[cmd_str] = task
        
        # Wait for all tasks
        for cmd_str, task in tasks.items():
            try:
                results[cmd_str] = await asyncio.wait_for(task, timeout=self._timeout)
            except asyncio.TimeoutError:
                self._log.warning(f"Command timeout: {cmd_str[:50]}")
                results[cmd_str] = ""
            except Exception as e:
                self._log.debug(f"Command error: {e}")
                results[cmd_str] = ""
        
        return results
    
    async def _run_command(self, cmd: list) -> str:
        """Execute single command"""
        try:
            import subprocess
            result = subprocess.run(
                cmd,
                capture_output=True,
                timeout=self._timeout,
                text=True
            )
            return result.stdout if result.returncode == 0 else ""
        except Exception as e:
            self._log.debug(f"Error running command: {e}")
            return ""


# Global cache instances
_command_cache = CommandCache()
_batch_executor = BatchExecutor()


def get_command_cache() -> CommandCache:
    """Get global command cache"""
    return _command_cache


def get_batch_executor() -> BatchExecutor:
    """Get global batch executor"""
    return _batch_executor
