#!/usr/bin/env python3
"""
Docker Monitor - Network and system utilities
Author: David Smidke - Accenture
Generated by GitHub Copilot

System information, network statistics, and command execution utilities.
"""

import asyncio
import logging
import os
import re
import subprocess
import time
from pathlib import Path
from typing import Dict, Optional, Tuple, List, Any
from docker_models import HostNetwork


def check_docker_permissions() -> Tuple[bool, str]:
    """Check if user has Docker access - Generated by GitHub Copilot
    
    Returns: (has_access: bool, message: str)
    """
    try:
        # Try to run docker ps to verify access
        result = subprocess.run(
            ["docker", "ps"],
            capture_output=True,
            timeout=3
        )
        
        if result.returncode == 0:
            return True, "Docker access OK"
        
        stderr = result.stderr.decode('utf-8', errors='ignore').lower()
        
        # Check for permission denied
        if "permission denied" in stderr or "permission denied" in result.stdout.decode('utf-8', errors='ignore').lower():
            return False, "Permission denied - user not in docker group"
        
        # Check for connection refused
        if "connection refused" in stderr or "cannot connect" in stderr:
            return False, "Docker daemon not responding - is Docker running?"
        
        return False, f"Docker check failed: {result.stderr.decode('utf-8', errors='ignore')[:100]}"
    
    except FileNotFoundError:
        return False, "Docker not found - is Docker installed?"
    except subprocess.TimeoutExpired:
        return False, "Docker check timed out"
    except Exception as e:
        return False, f"Error checking Docker: {str(e)}"


class CommandExecutor:
    """Safe subprocess execution with timeouts - Generated by GitHub Copilot"""
    
    def __init__(self, timeout: int = 5):
        self._timeout = timeout
        self._log = logging.getLogger(__name__)
    
    async def run(self, cmd: List[str], timeout: Optional[int] = None) -> str:
        """Execute command asynchronously with timeout - Generated by GitHub Copilot
        
        Security: Subprocess killed on timeout to prevent orphaned processes.
        """
        effective_timeout = timeout or self._timeout
        proc = None
        try:
            proc = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=effective_timeout)
            return stdout.decode('utf-8', errors='ignore')
        except asyncio.TimeoutError:
            if proc is not None:
                try:
                    proc.kill()
                    await proc.wait()
                except ProcessLookupError:
                    pass
            self._log.debug(f"Command timed out: {' '.join(cmd)}")
        except FileNotFoundError:
            self._log.debug(f"Command not found: {cmd[0]}")
        except Exception as e:
            self._log.error(f"Error running {' '.join(cmd)}: {e}")
        return ""
    
    def run_sync(self, cmd: List[str], timeout: Optional[int] = None) -> str:
        """Execute command synchronously (blocking)"""
        effective_timeout = timeout or self._timeout
        try:
            result = subprocess.run(cmd, capture_output=True, timeout=effective_timeout, check=False)
            return result.stdout.decode('utf-8', errors='ignore')
        except subprocess.TimeoutExpired:
            self._log.debug(f"Command timed out: {' '.join(cmd)}")
        except FileNotFoundError:
            self._log.debug(f"Command not found: {cmd[0]}")
        except Exception as e:
            self._log.error(f"Error: {e}")
        return ""


class SystemInfo:
    """System-level information and utilities - Generated by GitHub Copilot"""
    __slots__ = ('executor', 'boot_time', '_cache', '_cache_time')
    
    def __init__(self, timeout: int = 5):
        self.executor = CommandExecutor(timeout)
        self.boot_time = self._get_boot_time()
        self._cache: Dict[str, Tuple[Any, float]] = {}
        self._cache_time = 30  # Cache for 30 seconds
    
    @staticmethod
    def _get_boot_time() -> float:
        """Get system boot time"""
        try:
            with open("/proc/stat", "r") as f:
                for line in f:
                    if line.startswith("btime"):
                        return float(line.split()[1])
        except Exception:
            pass
        return time.time()
    
    async def get_cpu_count(self) -> int:
        """Get number of CPU cores"""
        try:
            return os.cpu_count() or 1
        except Exception:
            return 1
    
    async def get_memory_info(self) -> Dict[str, int]:
        """Get system memory information"""
        try:
            with open('/proc/meminfo', 'r') as f:
                mem_info = {}
                for line in f:
                    parts = line.split()
                    if parts:
                        mem_info[parts[0].lower().rstrip(':')] = int(parts[1]) * 1024
                return mem_info
        except Exception:
            return {}
    
    async def get_uptime(self) -> float:
        """Get system uptime in seconds"""
        try:
            with open('/proc/uptime', 'r') as f:
                return float(f.read().split()[0])
        except Exception:
            return 0.0
    
    async def get_load_average(self) -> Tuple[float, float, float]:
        """Get system load average"""
        try:
            with open('/proc/loadavg', 'r') as f:
                values = f.read().split()[:3]
                parsed = [float(v) for v in values]
                while len(parsed) < 3:
                    parsed.append(0.0)
                return (parsed[0], parsed[1], parsed[2])
        except Exception:
            return (0.0, 0.0, 0.0)


class NetworkStatsCollector:
    """Collect network interface statistics - Generated by GitHub Copilot"""
    __slots__ = ('executor', '_prev_rx', '_prev_tx', '_prev_time', '_interface', '_log')
    
    def __init__(self, timeout: int = 5):
        self.executor = CommandExecutor(timeout)
        self._prev_rx = 0
        self._prev_tx = 0
        self._prev_time = 0.0
        self._interface = ""
        self._log = logging.getLogger(__name__)
    
    async def detect_interface(self) -> str:
        """Auto-detect primary network interface"""
        if self._interface:
            return self._interface
        
        try:
            # Try to find interface from default route
            routes = await self.executor.run(["ip", "route", "show", "default"])
            if "dev" in routes:
                parts = routes.split()
                if "dev" in parts:
                    idx = parts.index("dev")
                    if idx + 1 < len(parts):
                        iface = parts[idx + 1]
                        # Verify interface exists
                        if os.path.exists(f"/sys/class/net/{iface}"):
                            self._interface = iface
                            return iface
        except Exception:
            pass
        
        # Fallback: find first UP interface
        try:
            sys_net = Path("/sys/class/net")
            if sys_net.exists():
                for iface in sorted(sys_net.iterdir()):
                    if iface.name not in ['lo', 'docker0']:
                        operstate = (iface / "operstate").read_text().strip()
                        if operstate == 'up':
                            self._interface = iface.name
                            return iface.name
        except Exception:
            pass
        
        # Final fallback
        self._interface = "eth0"
        return "eth0"
    
    async def collect_stats(self) -> HostNetwork:
        """Collect network throughput statistics"""
        stats = HostNetwork()
        
        interface = await self.detect_interface()
        stats.interface = interface
        
        now = time.time()
        
        try:
            rx_path = Path(f"/sys/class/net/{interface}/statistics/rx_bytes")
            tx_path = Path(f"/sys/class/net/{interface}/statistics/tx_bytes")
            
            if rx_path.exists() and tx_path.exists():
                rx = int(rx_path.read_text().strip())
                tx = int(tx_path.read_text().strip())
                
                if self._prev_time > 0:
                    dt = now - self._prev_time
                    if dt > 0:
                        stats.rx_bytes_sec = (rx - self._prev_rx) / dt
                        stats.tx_bytes_sec = (tx - self._prev_tx) / dt
                
                self._prev_rx = rx
                self._prev_tx = tx
                self._prev_time = now
        except Exception as e:
            self._log.debug(f"Error collecting network stats: {e}")
        
        return stats


class UpdateChecker:
    """Check for application and Docker image updates - Generated by GitHub Copilot"""
    
    def __init__(self, timeout: int = 10):
        self.executor = CommandExecutor(timeout)
        self._log = logging.getLogger(__name__)
    
    async def check_app_updates(self, current_version: str) -> Dict[str, Any]:
        """Check GitHub releases for new versions
        
        Security: Only checks official GitHub releases
        """
        try:
            import urllib.request
            import json
            
            url = "https://api.github.com/repos/accenture/docker-monitor/releases/latest"
            try:
                with urllib.request.urlopen(url, timeout=5) as response:
                    data = json.loads(response.read().decode())
                    latest_version = data.get('tag_name', '').lstrip('v')
                    
                    if latest_version and latest_version != current_version:
                        return {
                            'available': True,
                            'version': latest_version,
                            'url': data.get('html_url', ''),
                            'notes': data.get('body', '')
                        }
            except Exception as e:
                self._log.debug(f"Update check failed: {e}")
        except Exception as e:
            self._log.error(f"Update checker error: {e}")
        
        return {'available': False}
    
    async def check_image_updates(self, image_name: str) -> bool:
        """Check if Docker image has updates available"""
        try:
            # Pull latest manifest without actually pulling the image
            output = await self.executor.run(["docker", "pull", "--dry-run", image_name])
            return "already exists" not in output.lower()
        except Exception:
            return False
    
    async def get_outdated_containers(self) -> List[str]:
        """Identify containers running outdated images"""
        outdated = []
        
        try:
            # Get all containers
            containers_output = await self.executor.run(["docker", "ps", "-a", "--format", "{{.ID}}|{{.Image}}"])
            
            for line in containers_output.splitlines():
                parts = line.split('|')
                if len(parts) == 2:
                    container_id, image_name = parts
                    # Check if image has updates
                    if await self.check_image_updates(image_name):
                        outdated.append(container_id[:12])
        except Exception as e:
            self._log.debug(f"Error checking outdated containers: {e}")
        
        return outdated
